Here's a simplified design for a complete database query engine in Go. Note that this is a high-level overview and will require additional work to fully implement.

**Database Query Engine Design**

The database query engine will consist of the following components:

1. **Parser**: Responsible for parsing SQL queries into an Abstract Syntax Tree (AST).
2. **Optimizer**: Takes the AST and generates an optimized execution plan.
3. **Executor**: Executes the optimized execution plan against in-memory data structures with indexing.

**Database Query Engine Code**
```go
package db

import (
	"fmt"
	"log"

	"github.com/antlr/antlr4/runtime/Go/antlr/v4"
)

// Database represents the database instance
type Database struct {
	schemas map[string]*Schema
}

// Schema represents a database schema
type Schema struct {
	tables map[string]*Table
	indexes map[string]*Index
}

// Table represents a database table
type Table struct {
	name string
	data []Row
}

// Index represents a database index
type Index struct {
	name string
	columns []string
	rows   []int
}

// Row represents a single row in the table
type Row struct {
	values map[string]interface{}
}

// DatabaseQueryEngine is the main query engine component
type DatabaseQueryEngine struct {
	db *Database
}

func NewDatabaseQueryEngine(db *Database) *DatabaseQueryEngine {
	return &DatabaseQueryEngine{db: db}
}

// Parse parses a SQL query into an AST
func (q *DatabaseQueryEngine) Parse(query string) (*AST, error) {
	lexer := antlr.NewInputStreamLexer(query)
	stream := antlr.NewCommonTokenStream(lexer.GetTokens())
	p := NewParser(stream)

	ast, err := p.Parse()
	if err != nil {
		return nil, err
	}
	return ast, nil
}

// Optimize generates an optimized execution plan from the AST
func (q *DatabaseQueryEngine) Optimize(ast *AST) (*ExecutionPlan, error) {
	op := NewOptimizer()

	return op.Optimize(ast), nil
}

// Execute executes the optimized execution plan against in-memory data structures with indexing
func (q *DatabaseQueryEngine) Execute(plan *ExecutionPlan) ([]Row, error) {
	for _, step := range plan.Steps {
		switch step.Type {
		case "SELECT":
			rows, err := q.Select(step, plan.Input)
			if err != nil {
				return nil, err
			}
			return rows, nil

		case "INSERT":
			err := q.Insert(step, plan.Input)
			if err != nil {
				return nil, err
			}

		case "UPDATE":
			err := q.Update(step, plan.Input)
			if err != nil {
				return nil, err
			}

		default:
			return nil, fmt.Errorf("unknown operation type: %s", step.Type)
		}
	}
	return nil, nil
}

// Select executes a SELECT query against the in-memory data structures with indexing
func (q *DatabaseQueryEngine) Select(step *Step, input []Row) ([]Row, error) {
	var result []Row

	for _, row := range input {
		if matches, err := q.matchConditions(row, step.Conditions); err != nil {
			return nil, err
		} else if !matches {
			continue
		}

		result = append(result, row)
	}

	return result, nil
}

// Insert executes an INSERT query against the in-memory data structures with indexing
func (q *DatabaseQueryEngine) Insert(step *Step, input []Row) error {
	for _, row := range input {
		if !q.insertRow(row, step.Table, step.Columns) {
			return fmt.Errorf("insert failed for row: %v", row)
		}
	}

	return nil
}

// Update executes an UPDATE query against the in-memory data structures with indexing
func (q *DatabaseQueryEngine) Update(step *Step, input []Row) error {
	for _, row := range input {
		if !q.updateRow(row, step.Table, step.Columns, step.Values) {
			return fmt.Errorf("update failed for row: %v", row)
		}
	}

	return nil
}

// matchConditions checks if a row matches the conditions of a SELECT query
func (q *DatabaseQueryEngine) matchConditions(row Row, conditions []Condition) (bool, error) {
	for _, cond := range conditions {
		if !row.matchesCond(cond) {
			return false, nil
		}
	}

	return true, nil
}

// insertRow inserts a single row into the in-memory data structures with indexing
func (q *DatabaseQueryEngine) insertRow(row Row, table string, columns []string) bool {
	t := q.db.schemas[table].tables[0]

	// Add the new row to the table's data structure
	t.data = append(t.data, row)

	return true
}

// updateRow updates a single row in the in-memory data structures with indexing
func (q *DatabaseQueryEngine) updateRow(row Row, table string, columns []string, values map[string]interface{}) bool {
	t := q.db.schemas[table].tables[0]

	// Find the index of the row to update
	idx := t.findIndexByValues(row)

	if idx == -1 {
		return false
	}

	for col, val := range values {
		t.data[idx][col] = val
	}

	return true
}
```
**AST (Abstract Syntax Tree) Definition**
```go
type AST struct {
	Node interface{}
	Children []*AST
}
```
**Parser Code**
```go
package parser

import (
	"github.com/antlr/antlr4/runtime/Go/antlr/v4"
)

func NewParser(input antlr.TokenStream) *Parser {
	return &Parser{input: input}
}

func (p *Parser) Parse() (*AST, error) {
	ast := p.parseQuery()
	return ast, nil
}

func (p *Parser) parseQuery() (*AST, error) {
	// Implement parser logic here...
}
```
**Optimizer Code**
```go
package optimizer

import (
	"github.com/antlr/antlr4/runtime/Go/antlr/v4"
)

type Optimizer struct{}

func NewOptimizer() *Optimizer {
	return &Optimizer{}
}

func (o *Optimizer) Optimize(ast *AST) (*ExecutionPlan, error) {
	// Implement optimizer logic here...
}
```
This is a simplified example to demonstrate the high-level architecture of a database query engine in Go. The actual implementation will require more complexity and nuance.

Note that this design uses the following:

* The `Database` struct represents the database instance with its schema, tables, and indexes.
* The `AST` (Abstract Syntax Tree) is used to represent the parsed SQL query.
* The `Parser` is responsible for parsing the SQL query into an AST.
* The `Optimizer` generates an optimized execution plan from the AST.
* The `Executor` executes the optimized execution plan against in-memory data structures with indexing.

This design provides a basic structure for building a database query engine, but it requires significant additional implementation to fully support various SQL queries and features.